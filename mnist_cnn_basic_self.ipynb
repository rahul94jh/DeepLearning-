{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnist_cnn_basic_self.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN6qVmw3cd8lg+7pyTp3U5b"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkHU2GwL03g4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPool2D\n",
        "from keras import backend as k\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIvqMDBQ1Ggo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c5e97cb3-fa5d-46da-e2e7-b576ca6ca59f"
      },
      "source": [
        "tf.__version__ , keras.__version__"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('2.3.0', '2.4.3')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fd4kl7lF2G1_",
        "colab_type": "text"
      },
      "source": [
        "## 1. Importing Libraries and the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwsSd-0H1_wQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "3e26e162-529c-472e-9ac5-8a77fcc1b8d2"
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n",
            "(60000,)\n",
            "(10000, 28, 28)\n",
            "(10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQhF3Hu92sz7",
        "colab_type": "text"
      },
      "source": [
        "## 2. Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0GNOAi428ft",
        "colab_type": "text"
      },
      "source": [
        "#### 2.1 Reshape the Data\n",
        "First, let's understand the shape in which the network expects the training data. Since we have 60,000 training samples each of size (28, 28, 1), the training data (x_train) needs to be of the shape (60000, 28, 28, 1). If the images were coloured, the shape would have been (60000, 28, 28, 3).\n",
        "\n",
        "Further, each of the 60,000 images have a 0-9 label, so y_train needs to be of the shape (60000, 10) where each image's label is represented as a 10-d one-hot encoded vector.\n",
        "\n",
        "The shapes of x_test and y_test will be the same as that of x_train and y_train respectively."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8TeFvAO2gDv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "29912bcb-785b-4096-c4ab-4c41d91d0914"
      },
      "source": [
        "# shape which \n",
        "X_train = X_train.reshape(X_train.shape[0],X_train.shape[1],X_train.shape[2],1)\n",
        "X_test = X_test.reshape(X_test.shape[0],X_test.shape[1],X_test.shape[2],1)\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28, 1)\n",
            "(10000, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_vWp3N93kYH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "fe77cf1f-c43d-405c-d1b5-eb3fc45d3e7f"
      },
      "source": [
        "y_train = keras.utils.to_categorical(y_train,10)\n",
        "y_test = keras.utils.to_categorical(y_test,10)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 10)\n",
            "(10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkpQWgNj5DxR",
        "colab_type": "text"
      },
      "source": [
        "#### 2.2 Converting Input Data Type: Int to Float\n",
        "The pixels are originally stored as type `int`, but it is advisable to feed the data as `float`. This is not really compulsory, but advisable. You can read <a href=\"https://datascience.stackexchange.com/questions/13636/neural-network-data-type-conversion-float-from-int\">why conversion from int to float is helpful here</a>."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhDbiQYk5JBL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nksyVuyl4fCA",
        "colab_type": "text"
      },
      "source": [
        "#### 2.3 Rescaling (Normalisation)\n",
        "The value of each pixel is between 0-255, so we will **rescale each pixel** by dividing by 255 so that the range becomes 0-1. Recollect <a href=\"https://stats.stackexchange.com/questions/185853/why-do-we-need-to-normalize-the-images-before-we-put-them-into-cnn\">why normalisation is important for training NNs</a>."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Yc9KyPt4cMX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c32a034b-d161-404a-b1a7-403a7237627a"
      },
      "source": [
        "X_train.max(), X_train.min()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(255.0, 0.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1z18-D5a4z0a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train /= X_train.max()\n",
        "X_test /= X_test.max()"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPOyL_Op5qWZ",
        "colab_type": "text"
      },
      "source": [
        "## 3. Building the Model\n",
        "\n",
        "Let's now build the CNN architecture. For the MNIST dataset, we do not need to build a very sophisticated CNN - a simple shallow-ish CNN would suffice. \n",
        "\n",
        "We will build a network with:\n",
        "- two convolutional layers having 32 and 64 filters respectively, \n",
        "- followed by a max pooling layer, \n",
        "- and then `Flatten` the output of the pooling layer to give us a long vector, \n",
        "- then add a fully connected `Dense` layer with 128 neurons, and finally\n",
        "- add a `softmax` layer with 10 neurons\n",
        "\n",
        "The generic way to build a model in Keras is to instantiate a `Sequential` model and keep adding `keras.layers` to it. We will also use some dropouts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75GcjycP7EOF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "304b62b4-cb51-4650-da80-3c80db680461"
      },
      "source": [
        "# specify input dimensions of each image\n",
        "img_rows, img_cols = X_train.shape[1],X_train.shape[2]\n",
        "input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "# batch size, number of classes, epochs\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 12\n",
        "\n",
        "input_shape"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpxrgqWy5h4g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "outputId": "cd5348a8-379d-4fbc-8e3e-795971fe8fbd"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32,\n",
        "                 (3,3),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "\n",
        "model.add(Conv2D(64,\n",
        "                 (3,3),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128,activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(num_classes,activation='softmax'))\n",
        "model.summary()\n",
        "\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_2 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 24, 24, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 9216)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               1179776   \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 1,199,882\n",
            "Trainable params: 1,199,882\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "quF0kXqt867x",
        "colab_type": "text"
      },
      "source": [
        "## 4. Fitting and Evaluating the Model\n",
        "\n",
        "Let's now compile and train the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gF1saZNYznnB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.RMSprop(0.01),\n",
        "              loss=keras.losses.categorical_crossentropy,\n",
        "              metrics=[tf.keras.metrics.CategoricalAccuracy()])"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7417dy7-8Z8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "9b791d30-951c-4109-a0fc-3ccba41b06c7"
      },
      "source": [
        "model.fit(X_train, \n",
        "          y_train, \n",
        "          batch_size=batch_size, \n",
        "          epochs=epochs, \n",
        "          validation_data=(X_test, y_test))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/12\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.3974 - categorical_accuracy: 0.9003 - val_loss: 0.0972 - val_categorical_accuracy: 0.9711\n",
            "Epoch 2/12\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.1443 - categorical_accuracy: 0.9609 - val_loss: 0.0624 - val_categorical_accuracy: 0.9814\n",
            "Epoch 3/12\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.1357 - categorical_accuracy: 0.9638 - val_loss: 0.0585 - val_categorical_accuracy: 0.9821\n",
            "Epoch 4/12\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.1380 - categorical_accuracy: 0.9653 - val_loss: 0.0772 - val_categorical_accuracy: 0.9821\n",
            "Epoch 5/12\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.1359 - categorical_accuracy: 0.9664 - val_loss: 0.0624 - val_categorical_accuracy: 0.9827\n",
            "Epoch 6/12\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.1438 - categorical_accuracy: 0.9647 - val_loss: 0.0648 - val_categorical_accuracy: 0.9835\n",
            "Epoch 7/12\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.1537 - categorical_accuracy: 0.9642 - val_loss: 0.0820 - val_categorical_accuracy: 0.9838\n",
            "Epoch 8/12\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.1480 - categorical_accuracy: 0.9659 - val_loss: 0.0598 - val_categorical_accuracy: 0.9843\n",
            "Epoch 9/12\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.1583 - categorical_accuracy: 0.9631 - val_loss: 0.0677 - val_categorical_accuracy: 0.9846\n",
            "Epoch 10/12\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.1651 - categorical_accuracy: 0.9620 - val_loss: 0.0725 - val_categorical_accuracy: 0.9808\n",
            "Epoch 11/12\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.1695 - categorical_accuracy: 0.9611 - val_loss: 0.0723 - val_categorical_accuracy: 0.9820\n",
            "Epoch 12/12\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.1773 - categorical_accuracy: 0.9604 - val_loss: 0.0578 - val_categorical_accuracy: 0.9850\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1b2e3f6f60>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UqIS58xFdaN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "169a89c0-ceda-4427-ba42-cb91d83c66d3"
      },
      "source": [
        "# evaluate the model on test data\n",
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0578 - categorical_accuracy: 0.9850\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.05782555043697357, 0.9850000143051147]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    }
  ]
}